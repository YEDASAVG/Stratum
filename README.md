# Log Intelligence System

AI-powered log analysis with semantic search, anomaly detection, and root cause analysis.

## Status: Phase 1 Complete âœ… | Phase 2 Next ğŸš€

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  logai-api  â”‚â”€â”€â”€â”€â–¶â”‚   NATS   â”‚â”€â”€â”€â”€â–¶â”‚ logai-workerâ”‚
â”‚  (HTTP)     â”‚     â”‚  (Queue) â”‚     â”‚ (Processing)â”‚
â”‚  :3000      â”‚     â”‚  :4222   â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                      â”‚                      â”‚
                    â–¼                      â–¼                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ClickHouseâ”‚          â”‚  Qdrant  â”‚          â”‚  Ollama  â”‚
              â”‚  :8123   â”‚          â”‚  :6333   â”‚          â”‚  :11434  â”‚
              â”‚ (Logs) âœ… â”‚          â”‚(Vectors) â”‚          â”‚  (LLM)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Component | Technology | Status |
|-----------|------------|--------|
| Language | Rust | âœ… |
| HTTP Server | Axum 0.8 | âœ… |
| Message Queue | NATS 2.10 | âœ… |
| Log Storage | ClickHouse 24.1 | âœ… |
| Vector DB | Qdrant 1.7 | ğŸ”œ Phase 2 |
| Embeddings | FastEmbed (384D) | ğŸ”œ Phase 2 |
| LLM | Ollama (local) | ğŸ”œ Phase 4 |

## Project Structure

```
log-intelligence/
â”œâ”€â”€ Cargo.toml              # Workspace root
â”œâ”€â”€ docker-compose.yml      # NATS, ClickHouse, Qdrant
â””â”€â”€ crates/
    â”œâ”€â”€ logai-core/         # Shared types (LogEntry, LogLevel, etc.)
    â”œâ”€â”€ logai-api/          # HTTP API (POST /api/logs)
    â”œâ”€â”€ logai-worker/       # NATS consumer â†’ ClickHouse
    â””â”€â”€ logai-cli/          # CLI tool (coming soon)
```

## Phase Progress

### âœ… Phase 1: Foundation & Ingestion (Complete)
- [x] Project setup with Rust workspace
- [x] Log data models (LogEntry, RawLogEntry, LogLevel, ErrorCategory, LogChunk)
- [x] HTTP Ingestion API (POST /api/logs)
- [x] NATS integration (publish/subscribe)
- [x] ClickHouse storage (11 columns)
- [ ] Basic CLI (optional)

### ğŸ”œ Phase 2: Vector Search & Embeddings
- [ ] Qdrant collection setup
- [ ] Chunking strategy (time-window grouping)
- [ ] FastEmbed integration (384D vectors)
- [ ] Hybrid search API (semantic + filters)

### ğŸ“‹ Phase 3: Anomaly Detection & Alerting
- [ ] Statistical anomaly detection
- [ ] Slack integration
- [ ] Alert management API

### ğŸ“‹ Phase 4: RAG Query Engine
- [ ] Ollama/LLM integration
- [ ] Natural language queries
- [ ] Answer generation with sources

### ğŸ“‹ Phase 5: React Dashboard
- [ ] Log explorer with filters
- [ ] Real-time streaming
- [ ] AI chat interface

### ğŸ“‹ Phase 6: Production Polish
- [ ] Authentication
- [ ] Performance optimization
- [ ] Docker packaging

## Quick Start

### Prerequisites
- Rust 1.75+
- Docker & Docker Compose

### 1. Start Infrastructure
```bash
docker-compose up -d
```

### 2. Verify Services
```bash
curl http://localhost:8222/healthz   # NATS
curl http://localhost:8123/ping      # ClickHouse
curl http://localhost:6333/collections  # Qdrant
```

### 3. Build & Run

**Terminal 1 - Worker:**
```bash
cargo run --bin logai-worker
```

**Terminal 2 - API:**
```bash
cargo run --bin logai-api
```

### 4. Send Test Log
```bash
curl -X POST http://localhost:3000/api/logs \
  -H "Content-Type: application/json" \
  -d '{"message": "Payment failed for user 123", "level": "error", "service": "payment-service"}'
```

### 5. Verify in ClickHouse
```bash
curl "http://localhost:8123" -d "SELECT * FROM logai.logs FORMAT Pretty"
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/logs` | Ingest single log entry |

**Request:**
```json
{
  "message": "Error message here",
  "level": "error",
  "service": "my-service",
  "trace_id": "optional-trace-id",
  "fields": {"key": "value"}
}
```

**Response:**
```json
{
  "id": "uuid-here",
  "status": "accepted"
}
```

## Data Flow

```
1. Client POST /api/logs
          â”‚
          â–¼
2. logai-api receives JSON
   â€¢ Parse â†’ RawLogEntry
   â€¢ Enrich â†’ LogEntry (add id, timestamps)
   â€¢ Publish to NATS "logs.ingest"
   â€¢ Return {id, status: "accepted"}
          â”‚
          â–¼
3. NATS queue holds message
          â”‚
          â–¼
4. logai-worker subscribes
   â€¢ Receive from NATS
   â€¢ Parse â†’ LogEntry
   â€¢ INSERT into ClickHouse
          â”‚
          â–¼
5. ClickHouse stores log
   â€¢ 11 columns (id, timestamp, level, service, message, ...)
   â€¢ Partitioned by month
   â€¢ Sorted by (service, timestamp)
```

## Performance

- **Ingestion latency:** ~4ms (API to ClickHouse)
- **Throughput:** Tested up to 1000 logs/sec (single worker)

## License

MIT
